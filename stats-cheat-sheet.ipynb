{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Descriptive Statistics\n**Descriptive statistics summarize the main features of a dataset. Common measures include mean, median, mode, variance, standard deviation, and range.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Example dataframe\ndf = pd.DataFrame({\n    'age': [23, 25, 31, 35, 28],\n    'salary': [50000, 62000, 75000, 80000, 60000]\n})\n\n# Descriptive Statistics\nmean = df['salary'].mean()  # Mean\nmedian = df['salary'].median()  # Median\nmode = df['salary'].mode()  # Mode\nstd = df['salary'].std()  # Standard Deviation\nvar = df['salary'].var()  # Variance\nmin_value = df['salary'].min()  # Minimum\nmax_value = df['salary'].max()  # Maximum\nrange_value = max_value - min_value  # Range\n\n# Summary statistics\nsummary = df.describe()\n\n# Correlation and Covariance\ncorr = df.corr()  # Correlation matrix\ncov = df.cov()  # Covariance matrix\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Probability Distributions\n**Probability distributions describe how the values of a variable are distributed. Common distributions include normal (Gaussian), binomial, and Poisson.**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm, binom, poisson\n\n# Normal Distribution\nmu, sigma = 0, 1  # mean and standard deviation\nnormal_dist = norm.rvs(size=1000, loc=mu, scale=sigma)\n\n# Binomial Distribution\nn, p = 10, 0.5  # number of trials, probability of success\nbinomial_dist = binom.rvs(n, p, size=1000)\n\n# Poisson Distribution\nlambda_ = 3  # rate (lambda) for Poisson\npoisson_dist = poisson.rvs(mu=lambda_, size=1000)\n\n# Probability Density Function (PDF) for Normal\npdf_value = norm.pdf(0, loc=mu, scale=sigma)\n\n# Cumulative Distribution Function (CDF)\ncdf_value = norm.cdf(0, loc=mu, scale=sigma)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Confidence Intervals\n**Confidence intervals give a range in which the true population parameter is likely to lie with a given level of confidence (e.g., 95%).**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport scipy.stats as stats\n\n# Sample data\ndata = np.array([23, 25, 31, 35, 28])\nconfidence = 0.95\n\n# Mean and standard error of the mean\nmean = np.mean(data)\nsem = stats.sem(data)\n\n# Confidence interval\nconfidence_interval = stats.t.interval(confidence, len(data)-1, loc=mean, scale=sem)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Hypothesis Testing and T-Tests\n**Hypothesis testing helps in determining whether a sample data supports a given hypothesis. The T-test checks whether the means of two groups are statistically different.**\n\n* **One-sample T-test: Tests if the sample mean is equal to a population mean.**","metadata":{}},{"cell_type":"code","source":"# One-sample t-test\nt_stat, p_value = stats.ttest_1samp(data, popmean=30)  # Test if mean of data = 30","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Two-sample T-test: Tests if the means of two independent groups are different.**","metadata":{}},{"cell_type":"code","source":"# Two-sample t-test\ngroup1 = [23, 25, 31, 35, 28]\ngroup2 = [22, 29, 32, 30, 27]\nt_stat, p_value = stats.ttest_ind(group1, group2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Paired T-test: Tests if the means of two related groups are different.**","metadata":{}},{"cell_type":"code","source":"# Paired t-test\nbefore = [80, 75, 85, 90, 70]\nafter = [82, 78, 85, 95, 72]\nt_stat, p_value = stats.ttest_rel(before, after)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Chi-Squared Test\n**The Chi-Squared test assesses the association between categorical variables in a contingency table (observed vs. expected frequencies).**\n\n**Hypotheses:**\n\n***Null Hypothesis (H₀): The two categorical variables are independent (i.e., no association).***\n\n***Alternative Hypothesis (H₁): The two categorical variables are dependent (i.e., there is an association).***","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n# Contingency table (observed frequencies)\nobserved = [[10, 20, 30], [6, 9, 17]]\n\n# Chi-Squared test\nchi2, p_value, dof, expected = chi2_contingency(observed)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. General Hypothesis Testing Framework\n**In hypothesis testing:**\n\n* **Null Hypothesis (H0): Assumes no effect or difference.**\n\n* **Alternative Hypothesis (H1): Assumes there is an effect or difference.**\n\n* **P-value: Helps in deciding whether to reject the null hypothesis.**\n\n* **Reject H0 if p_value < alpha (usually 0.05).**","metadata":{}},{"cell_type":"markdown","source":"# 7. Critical Values for T-Test\n**Critical values help determine the rejection region for the null hypothesis based on a given confidence level.**","metadata":{}},{"cell_type":"code","source":"# Critical t-value for a two-tailed test at 95% confidence and df=10\nalpha = 0.05\ncritical_value = stats.t.ppf(1 - alpha/2, df=10)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 8. One-Way ANOVA (Analysis of Variance):\n**Purpose:** *One-way ANOVA is used to determine if there are statistically significant differences between the means of three or more independent groups.*\n\n**When to Use:** *You use ANOVA when you want to test whether the means of several groups are equal. It checks for overall differences across all groups, but it doesn’t tell you which specific groups differ from each other.*\n\n**How it Works:** *It compares the variability within groups to the variability between groups. If the variability between groups is significantly larger than the variability within groups, it suggests that there are differences between the groups.*\n\n**Limitations:** *One-way ANOVA only tells you that there is at least one significant difference between the groups, but it doesn’t specify which groups differ.*","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport pandas as pd\nimport statsmodels.api as sm\nfrom statsmodels.formula.api import ols\nfrom statsmodels.stats.multicomp import pairwise_tukeyhsd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Load a sample dataset from seaborn (e.g., \"tips\" dataset)\n# This dataset contains information about tips received at a restaurant.\ndf = sns.load_dataset('tips')\n\n# Display the first few rows to understand the structure\nprint(df.head())\n\n# One-way ANOVA: Does the mean tip vary by day?\n# Null hypothesis: The mean tip is the same across all days.\n# Alternative hypothesis: At least one day has a different mean tip.\n\n# Step 1: Define the model\n# We use the formula tip ~ day to indicate that we are checking how tip \n# (the dependent variable) varies by day (the independent variable).\nmodel = ols('tip ~ day', data=df).fit()\n\n# Step 2: Perform ANOVA\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(\"One-Way ANOVA Table:\")\nprint(anova_table)\n\n# Interpretation: Check the p-value in the ANOVA table to see if there's a significant difference.\n# If p < 0.05, reject the null hypothesis (there is a significant difference in tips across the days).\n\n# Step 3: Tukey's HSD Test to identify which days differ significantly\ntukey = pairwise_tukeyhsd(df['tip'], df['day'], alpha=0.05)\nprint(tukey)\n\n# Step 4: Plot the results for better visualization\ntukey.plot_simultaneous()\nplt.show()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 9. Two-Way ANOVA with Interaction and Tukey's Test\n\nA two-way ANOVA examines how two independent variables affect a dependent variable and also tests for interaction effects.","metadata":{}},{"cell_type":"code","source":"# Two-way ANOVA: Does the mean tip vary by both day and time (lunch or dinner)?\n# Null hypothesis: The mean tip is the same across all combinations of day and time.\n# Alternative hypothesis: There are differences in mean tips across day, time, or their interaction.\n\n# Step 1: Define the model (with interaction term day*time)\nmodel = ols('tip ~ day * time', data=df).fit()\n\n# Step 2: Perform Two-way ANOVA\nanova_table = sm.stats.anova_lm(model, typ=2)\nprint(\"Two-Way ANOVA Table:\")\nprint(anova_table)\n\n# Interpretation: Check the p-values for both the main effects (day, time) and the interaction term (day:time).\n# Significant p-values (< 0.05) indicate that these factors (or their combination) affect the dependent variable (tip).\n\n# Step 3: Tukey's Test for pairwise comparisons (for 'day')\ntukey_day = pairwise_tukeyhsd(df['tip'], df['day'], alpha=0.05)\nprint(\"Tukey's Test for 'day':\")\nprint(tukey_day)\n\n# Optional: Tukey's Test for pairwise comparisons (for 'time')\ntukey_time = pairwise_tukeyhsd(df['tip'], df['time'], alpha=0.05)\nprint(\"Tukey's Test for 'time':\")\nprint(tukey_time)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 10. Tukey's Test (Tukey's HSD):\n**Purpose:** *Tukey’s test is a post-hoc test, meaning it is applied after you find a significant result from ANOVA. It is used to determine exactly which groups differ from each other by comparing all pairs of group means.*\n\n**When to Use:** *You apply Tukey’s test when the ANOVA shows that there is a significant difference between group means, and you want to pinpoint the exact differences between specific pairs of groups.*\n\n**How it Works:** *Tukey's test calculates a confidence interval for the difference between each pair of group means. If the confidence interval does not contain zero, it indicates a significant difference between the groups.*\n\n**Result:** *Tukey’s test identifies specific pairs of groups where the means differ significantly, allowing for more detailed insights than ANOVA alone.*","metadata":{}},{"cell_type":"code","source":"import pingouin as pg\n\n# Performing Tukey's HSD test using pingouin\ntukey_pg = pg.pairwise_tukey(dv='tip', between='day', data=df)\nprint(\"Tukey's Test using pingouin:\")\nprint(tukey_pg)","metadata":{},"execution_count":null,"outputs":[]}]}