{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Descriptive Statistics\n**Descriptive statistics summarize the main features of a dataset. Common measures include mean, median, mode, variance, standard deviation, and range.**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\n# Example dataframe\ndf = pd.DataFrame({\n    'age': [23, 25, 31, 35, 28],\n    'salary': [50000, 62000, 75000, 80000, 60000]\n})\n\n# Descriptive Statistics\nmean = df['salary'].mean()  # Mean\nmedian = df['salary'].median()  # Median\nmode = df['salary'].mode()  # Mode\nstd = df['salary'].std()  # Standard Deviation\nvar = df['salary'].var()  # Variance\nmin_value = df['salary'].min()  # Minimum\nmax_value = df['salary'].max()  # Maximum\nrange_value = max_value - min_value  # Range\n\n# Summary statistics\nsummary = df.describe()\n\n# Correlation and Covariance\ncorr = df.corr()  # Correlation matrix\ncov = df.cov()  # Covariance matrix\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T09:28:48.503526Z","iopub.execute_input":"2024-09-24T09:28:48.504243Z","iopub.status.idle":"2024-09-24T09:28:49.597758Z","shell.execute_reply.started":"2024-09-24T09:28:48.504192Z","shell.execute_reply":"2024-09-24T09:28:49.596566Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# 2. Probability Distributions\n**Probability distributions describe how the values of a variable are distributed. Common distributions include normal (Gaussian), binomial, and Poisson.**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import norm, binom, poisson\n\n# Normal Distribution\nmu, sigma = 0, 1  # mean and standard deviation\nnormal_dist = norm.rvs(size=1000, loc=mu, scale=sigma)\n\n# Binomial Distribution\nn, p = 10, 0.5  # number of trials, probability of success\nbinomial_dist = binom.rvs(n, p, size=1000)\n\n# Poisson Distribution\nlambda_ = 3  # rate (lambda) for Poisson\npoisson_dist = poisson.rvs(mu=lambda_, size=1000)\n\n# Probability Density Function (PDF) for Normal\npdf_value = norm.pdf(0, loc=mu, scale=sigma)\n\n# Cumulative Distribution Function (CDF)\ncdf_value = norm.cdf(0, loc=mu, scale=sigma)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T09:29:56.763286Z","iopub.execute_input":"2024-09-24T09:29:56.763888Z","iopub.status.idle":"2024-09-24T09:29:57.302737Z","shell.execute_reply.started":"2024-09-24T09:29:56.763815Z","shell.execute_reply":"2024-09-24T09:29:57.301610Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 3. Confidence Intervals\n**Confidence intervals give a range in which the true population parameter is likely to lie with a given level of confidence (e.g., 95%).**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport scipy.stats as stats\n\n# Sample data\ndata = np.array([23, 25, 31, 35, 28])\nconfidence = 0.95\n\n# Mean and standard error of the mean\nmean = np.mean(data)\nsem = stats.sem(data)\n\n# Confidence interval\nconfidence_interval = stats.t.interval(confidence, len(data)-1, loc=mean, scale=sem)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-24T09:30:47.985641Z","iopub.execute_input":"2024-09-24T09:30:47.986299Z","iopub.status.idle":"2024-09-24T09:30:47.995936Z","shell.execute_reply.started":"2024-09-24T09:30:47.986252Z","shell.execute_reply":"2024-09-24T09:30:47.994662Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 4. Hypothesis Testing and T-Tests\n**Hypothesis testing helps in determining whether a sample data supports a given hypothesis. The T-test checks whether the means of two groups are statistically different.**\n\n* **One-sample T-test: Tests if the sample mean is equal to a population mean.**","metadata":{}},{"cell_type":"code","source":"# One-sample t-test\nt_stat, p_value = stats.ttest_1samp(data, popmean=30)  # Test if mean of data = 30","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Two-sample T-test: Tests if the means of two independent groups are different.**","metadata":{}},{"cell_type":"code","source":"# Two-sample t-test\ngroup1 = [23, 25, 31, 35, 28]\ngroup2 = [22, 29, 32, 30, 27]\nt_stat, p_value = stats.ttest_ind(group1, group2)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **Paired T-test: Tests if the means of two related groups are different.**","metadata":{}},{"cell_type":"code","source":"# Paired t-test\nbefore = [80, 75, 85, 90, 70]\nafter = [82, 78, 85, 95, 72]\nt_stat, p_value = stats.ttest_rel(before, after)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Chi-Squared Test\n**The Chi-Squared test assesses the association between categorical variables in a contingency table (observed vs. expected frequencies).**","metadata":{}},{"cell_type":"code","source":"from scipy.stats import chi2_contingency\n\n# Contingency table (observed frequencies)\nobserved = [[10, 20, 30], [6, 9, 17]]\n\n# Chi-Squared test\nchi2, p_value, dof, expected = chi2_contingency(observed)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. General Hypothesis Testing Framework\n**In hypothesis testing:**\n\n* **Null Hypothesis (H0): Assumes no effect or difference.**\n\n* **Alternative Hypothesis (H1): Assumes there is an effect or difference.**\n\n* **P-value: Helps in deciding whether to reject the null hypothesis.**\n\n* **Reject H0 if p_value < alpha (usually 0.05).**","metadata":{}},{"cell_type":"markdown","source":"# 7. Critical Values for T-Test\n**Critical values help determine the rejection region for the null hypothesis based on a given confidence level.**","metadata":{}},{"cell_type":"code","source":"# Critical t-value for a two-tailed test at 95% confidence and df=10\nalpha = 0.05\ncritical_value = stats.t.ppf(1 - alpha/2, df=10)","metadata":{},"execution_count":null,"outputs":[]}]}